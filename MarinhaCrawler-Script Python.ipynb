{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2ec27eb",
   "metadata": {},
   "source": [
    "### Python Crawler to receive notification when a update occurs - Script Module\n",
    "\n",
    "Requirements:\n",
    "* pip install python3\n",
    "* pip install sendgrid\n",
    "* pip install requests==2.22.0 beautifulsoup4==4.8.1\n",
    "\n",
    "This script expect you have the following files in the project directory\n",
    "\n",
    "* emailInformation.txt: Here you should add the From email address in the first line and the To email address in the second line\n",
    "* sendgrid.env must be in your git ignore file, and your API KEY must be saved in your environmental variables\n",
    "\n",
    "Source: \n",
    "* https://www.twilio.com/blog/web-scraping-and-parsing-html-in-python-with-beautiful-soup\n",
    "* https://www.geeksforgeeks.org/scheduling-python-scripts-on-linux/\n",
    "* https://app.sendgrid.com/guide/integrate/langs/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dcf0949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-27-[marinha]-No changes\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import requests\n",
    "import filecmp    \n",
    "import os\n",
    "\n",
    "#if your environment is not recognizing the correct library folder use this\n",
    "import sys\n",
    "sys.path.append(\"/Users/pauloalves/workspace/crawler/crawler/lib/python3.9/site-packages\")\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# using SendGrid's Python Library\n",
    "# https://github.com/sendgrid/sendgrid-python\n",
    "from sendgrid import SendGridAPIClient\n",
    "from sendgrid.helpers.mail import Mail\n",
    "\n",
    "from os.path import exists\n",
    "from datetime import date \n",
    "\n",
    "import shutil\n",
    "\n",
    "# params: \n",
    "#  _url: website address that you want to check\n",
    "#  _id: HTML tag that you want to explore\n",
    "def getContent(_url, _id):    \n",
    "    html_text = requests.get(_url).text\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    return soup.find(id=_id).text\n",
    "\n",
    "\n",
    "# params: \n",
    "#  _fileName: File name related to the file that you want to store the content\n",
    "#  _content: Content extracted from the website mentioned before \n",
    "def saveContent(_fileName,_content):\n",
    "    #open file\n",
    "    file = open(_fileName, \"w\")\n",
    "\n",
    "    #convert variable to string\n",
    "    file.write(repr(_content))\n",
    "\n",
    "    #close file\n",
    "    file.close()\n",
    "\n",
    "    \n",
    "# params: \n",
    "#  _file1: File that you want to compare\n",
    "#  _file2: File that you want to compare\n",
    "def compareContent(_file1, _file2):\n",
    "    #compare files\n",
    "    result = filecmp.cmp(_file1, _file2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# params: \n",
    "#  _subject: String related to the subject that this crawler will verify\n",
    "def sendMail(_subject):\n",
    "    f = open(\"emailInformation.txt\", \"r\")\n",
    "    _emailFrom = f.readline()\n",
    "    _emailTo = f.readline()\n",
    "\n",
    "    message = Mail(    \n",
    "        from_email=_emailFrom,\n",
    "        to_emails=_emailTo,\n",
    "        subject='Crawler Notification - '+_subject,\n",
    "        html_content='<strong>You have an update in the site that you are monitoring.</strong><br>https://www.marinha.mil.br/com1dn/smv/smv-principal<br>##webCrawler##')\n",
    "    try:\n",
    "        sg = SendGridAPIClient(os.environ.get('SENDGRID_API_KEY'))\n",
    "        response = sg.send(message)\n",
    "    except Exception as e:\n",
    "        print(e.message)\n",
    "\n",
    "## MAIN ##\n",
    "content = getContent('https://www.marinha.mil.br/com1dn/smv/smv-principal', \"node-652\")\n",
    "\n",
    "subject = \"marinha\"\n",
    "\n",
    "newFile = str(subject)+'New.txt'\n",
    "oldFile = str(subject)+'Old.txt'\n",
    "\n",
    "# verify if there is a source file to compare with the current website state\n",
    "if exists(oldFile)==False:\n",
    "    saveContent(oldFile, content)\n",
    "\n",
    "# save the current website state    \n",
    "saveContent(newFile, content)\n",
    "\n",
    "# store the result of file comparison. True if they are equal, False if they are not\n",
    "result = compareContent(oldFile,newFile)\n",
    "\n",
    "# verify the result, if false, send an email to notify the stakeholders informing that there is an update\n",
    "if result==False:\n",
    "    print(str(date.today())+'-['+subject+']-'+ 'Do something, there is an update in your site')\n",
    "    sendMail(str(subject))\n",
    "    shutil.copyfile(oldFile, str(date.today())+'-'+oldFile)\n",
    "    shutil.copyfile(newFile,oldFile)\n",
    "else:\n",
    "    print(str(date.today())+'-['+subject+']-'+'No changes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce7cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
